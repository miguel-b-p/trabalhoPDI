# ğŸš€ YOLO Benchmark System

Sistema completo de benchmark e testes de parÃ¢metros YOLO para anÃ¡lise de impacto no desempenho de modelos de detecÃ§Ã£o de objetos.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Uso RÃ¡pido](#uso-rÃ¡pido)
- [DocumentaÃ§Ã£o](#documentaÃ§Ã£o)
- [Exemplos](#exemplos)

## ğŸ¯ VisÃ£o Geral

Este projeto permite testar sistematicamente como diferentes parÃ¢metros do YOLO (epochs, batch size, learning rate, etc.) afetam o desempenho final do modelo. O sistema implementa um mecanismo inteligente de benchmark que divide o intervalo de cada parÃ¢metro em fraÃ§Ãµes (1/5, 2/5, 3/5, 4/5, 5/5) para anÃ¡lise detalhada.

## âœ¨ CaracterÃ­sticas

- **ğŸ—ï¸ Arquitetura MVC**: CÃ³digo organizado e modular
- **ğŸ“Š VisualizaÃ§Ãµes Interativas**: GrÃ¡ficos com Bokeh
- **ğŸ® Interface Jupyter**: Widgets interativos para controle total
- **ğŸ“ˆ AnÃ¡lise EstatÃ­stica**: CorrelaÃ§Ãµes e rankings de impacto
- **âš¡ ExecuÃ§Ã£o Paralela**: Suporte para mÃºltiplos workers
- **ğŸ’¾ PersistÃªncia**: Salva todos os resultados em JSON/CSV
- **ğŸ“ RelatÃ³rios AutomÃ¡ticos**: GeraÃ§Ã£o de relatÃ³rios detalhados
- **ğŸ”§ Altamente ConfigurÃ¡vel**: Todos os parÃ¢metros YOLO disponÃ­veis

## ğŸ“ Estrutura do Projeto

```
trabalhoPDI/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                 # Backend e lÃ³gica principal
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py        # ConfiguraÃ§Ãµes do sistema
â”‚   â”‚   â”œâ”€â”€ trainer.py       # Treinador YOLO
â”‚   â”‚   â”œâ”€â”€ benchmark.py     # Sistema de benchmark
â”‚   â”‚   â””â”€â”€ data_manager.py  # Gerenciamento de datasets
â”‚   â”‚
â”‚   â”œâ”€â”€ interface/           # Interface interativa
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ jupyter_interface.py  # Interface Jupyter com widgets
â”‚   â”‚
â”‚   â”œâ”€â”€ results/             # AnÃ¡lise e visualizaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ visualizer.py    # VisualizaÃ§Ãµes Bokeh
â”‚   â”‚   â””â”€â”€ analyzer.py      # AnÃ¡lise estatÃ­stica
â”‚   â”‚
â”‚   â”œâ”€â”€ models/              # Modelos treinados
â”‚   â””â”€â”€ data/                # Datasets
â”‚
â”œâ”€â”€ requirements.txt         # DependÃªncias
â”œâ”€â”€ README.md               # Este arquivo
â””â”€â”€ notebooks/              # Notebooks de exemplo
    â”œâ”€â”€ 01_quick_start.ipynb
    â”œâ”€â”€ 02_training.ipynb
    â”œâ”€â”€ 03_benchmark.ipynb
    â””â”€â”€ 04_analysis.ipynb
```

## ğŸ”§ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
cd /home/mingas/projetos/trabalhoPDI
```

### 2. Crie um ambiente virtual (recomendado)

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. (Opcional) Instale Euporie para terminal Jupyter

```bash
pip install euporie
```

## ğŸš€ Uso RÃ¡pido

### Interface Jupyter (Recomendado)

```python
from src.interface import YOLOBenchmarkInterface

# Inicializa interface
interface = YOLOBenchmarkInterface()

# Exibe interface interativa
interface.show()
```

### API Python

#### Treinamento Individual

```python
from src.core import Config, YOLOTrainer

# Configura
config = Config()
config.epochs = 100
config.batch_size = 16
config.imgsz = 640

# Treina
trainer = YOLOTrainer(config)
trainer.load_model('yolo11n.pt')
metrics = trainer.train(data='/path/to/data.yaml')

print(f"mAP50-95: {metrics['mAP50-95']:.2f}%")
```

#### Benchmark de ParÃ¢metros

```python
from src.core import Config, BenchmarkConfig, BenchmarkRunner

# ConfiguraÃ§Ã£o base
config = Config()

# ConfiguraÃ§Ã£o do benchmark
benchmark_config = BenchmarkConfig()
benchmark_config.benchmark_name = "epochs_benchmark"
benchmark_config.num_divisions = 5

# Define parÃ¢metros para testar
benchmark_config.benchmark_params = {
    'epochs': {'min': 10, 'max': 100, 'type': 'int'},
    'batch_size': {'min': 4, 'max': 32, 'type': 'int'},
    'lr0': {'min': 0.001, 'max': 0.1, 'type': 'float'}
}

# Executa benchmark
runner = BenchmarkRunner(config, benchmark_config)
results = runner.run_benchmark(
    dataset_path='/path/to/data.yaml',
    parallel=False
)

print(f"Testes concluÃ­dos: {results['successful_tests']}/{results['total_tests']}")
```

#### VisualizaÃ§Ã£o de Resultados

```python
from src.results import BenchmarkVisualizer, ResultsAnalyzer

# Carrega resultados
analyzer = ResultsAnalyzer(config.results_path)
benchmark_data = analyzer.load_benchmark('epochs_benchmark')

# Cria visualizaÃ§Ãµes
visualizer = BenchmarkVisualizer(config.results_path)
output_html = visualizer.visualize_benchmark(benchmark_data)

print(f"VisualizaÃ§Ã£o salva em: {output_html}")

# Gera relatÃ³rio
report = analyzer.generate_report(benchmark_data)
print(report)
```

## ğŸ“– DocumentaÃ§Ã£o Detalhada

### Sistema de Benchmark

O sistema de benchmark funciona da seguinte forma:

1. **DefiniÃ§Ã£o de ParÃ¢metros**: VocÃª especifica quais parÃ¢metros testar e seus intervalos (min/max)
2. **DivisÃµes AutomÃ¡ticas**: O sistema divide cada intervalo em N partes iguais (padrÃ£o: 5)
   - 1/5: 20% do intervalo
   - 2/5: 40% do intervalo
   - 3/5: 60% do intervalo
   - 4/5: 80% do intervalo
   - 5/5: 100% do intervalo (valor mÃ¡ximo)
3. **ExecuÃ§Ã£o**: Cada combinaÃ§Ã£o Ã© testada independentemente
4. **AnÃ¡lise**: Gera estatÃ­sticas, correlaÃ§Ãµes e rankings de impacto

### ParÃ¢metros DisponÃ­veis

#### Treinamento BÃ¡sico
- `epochs`: NÃºmero de Ã©pocas (padrÃ£o: 100)
- `batch_size`: Tamanho do batch (padrÃ£o: 16)
- `imgsz`: Tamanho da imagem (padrÃ£o: 640)
- `device`: Dispositivo (cuda, cpu, mps)

#### OtimizaÃ§Ã£o
- `optimizer`: Otimizador (SGD, Adam, AdamW)
- `lr0`: Learning rate inicial (padrÃ£o: 0.01)
- `lrf`: Learning rate final (padrÃ£o: 0.01)
- `momentum`: Momentum (padrÃ£o: 0.937)
- `weight_decay`: Weight decay (padrÃ£o: 0.0005)

#### Data Augmentation
- `augment`: Habilita/desabilita augmentation
- `hsv_h`, `hsv_s`, `hsv_v`: Augmentation HSV
- `degrees`: RotaÃ§Ã£o
- `translate`: TranslaÃ§Ã£o
- `scale`: Escala
- `fliplr`: Flip horizontal
- `mosaic`: Mosaic augmentation
- `mixup`: Mixup augmentation

### MÃ©tricas Analisadas

- **mAP50**: Mean Average Precision @ IoU 0.50
- **mAP50-95**: Mean Average Precision @ IoU 0.50:0.95
- **Precision**: PrecisÃ£o do modelo
- **Recall**: Recall do modelo
- **Training Time**: Tempo de treinamento

## ğŸ“Š VisualizaÃ§Ãµes

O sistema gera visualizaÃ§Ãµes interativas com Bokeh:

1. **VisÃ£o Geral**: EstatÃ­sticas do benchmark
2. **AnÃ¡lise por ParÃ¢metro**: Impacto individual de cada parÃ¢metro
3. **ComparaÃ§Ã£o de MÃ©tricas**: Scatter plots e comparaÃ§Ãµes
4. **Timeline**: Tempo de execuÃ§Ã£o dos testes

## ğŸ“ Exemplos

### Exemplo 1: Benchmark de Epochs

```python
benchmark_config = BenchmarkConfig()
benchmark_config.benchmark_params = {
    'epochs': {'min': 10, 'max': 100, 'type': 'int'}
}
benchmark_config.num_divisions = 5

# Testa: 10, 28, 46, 64, 82, 100 epochs
```

### Exemplo 2: Benchmark de MÃºltiplos ParÃ¢metros

```python
benchmark_config = BenchmarkConfig()
benchmark_config.benchmark_params = {
    'epochs': {'min': 10, 'max': 50, 'type': 'int'},
    'batch_size': {'min': 8, 'max': 32, 'type': 'int'},
    'optimizer': {'values': ['SGD', 'Adam', 'AdamW'], 'type': 'categorical'}
}

# Total de testes: 5 (epochs) + 5 (batch_size) + 3 (optimizer) = 13 testes
```

### Exemplo 3: AnÃ¡lise de Impacto

```python
analyzer = ResultsAnalyzer(config.results_path)
benchmark_data = analyzer.load_benchmark('my_benchmark')

# Analisa impacto de um parÃ¢metro
impact = analyzer.analyze_parameter_impact(benchmark_data, 'epochs', 'mAP50-95')
print(f"CorrelaÃ§Ã£o: {impact['correlation']['coefficient']:.3f}")
print(f"Melhor valor: {impact['best']['value']} (Score: {impact['best']['score']:.2f}%)")

# Ranking de parÃ¢metros
rankings = analyzer.rank_parameters(benchmark_data)
for i, rank in enumerate(rankings, 1):
    print(f"{i}. {rank['parameter']} (Impact: {rank['impact_score']:.3f})")

# ConfiguraÃ§Ã£o Ã³tima
optimal = analyzer.find_optimal_configuration(benchmark_data)
print(f"ConfiguraÃ§Ã£o Ã³tima: {optimal['parameter']}={optimal['value']}")
```

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

## ğŸ‘¥ Autores

- **YOLO Benchmark Team**

## ğŸ™ Agradecimentos

- [Ultralytics YOLO](https://github.com/ultralytics/ultralytics)
- [Bokeh](https://bokeh.org/)
- [Jupyter Project](https://jupyter.org/)

## ğŸ“ Suporte

Para questÃµes e suporte, abra uma issue no repositÃ³rio do projeto.

---

**Nota**: Este projeto foi desenvolvido seguindo as melhores prÃ¡ticas de programaÃ§Ã£o Python e padrÃ£o MVC para garantir cÃ³digo limpo, organizado e de fÃ¡cil manutenÃ§Ã£o.
