{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÅ Sistema de Benchmark - YOLO\n",
    "\n",
    "Este notebook demonstra o sistema completo de benchmark que testa automaticamente como diferentes par√¢metros afetam o desempenho do modelo.\n",
    "\n",
    "## Como Funciona\n",
    "\n",
    "O sistema divide cada par√¢metro em fra√ß√µes:\n",
    "- 1/5: 20% do intervalo (min + 0.2 √ó range)\n",
    "- 2/5: 40% do intervalo (min + 0.4 √ó range)\n",
    "- 3/5: 60% do intervalo (min + 0.6 √ó range)\n",
    "- 4/5: 80% do intervalo (min + 0.8 √ó range)\n",
    "- 5/5: 100% do intervalo (valor m√°ximo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.core import Config, BenchmarkConfig, BenchmarkRunner\n",
    "\n",
    "print(\"‚úÖ Imports realizados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o principal\n",
    "config = Config(project_root=project_root)\n",
    "config.model_name = 'yolo11n.pt'\n",
    "config.device = 'cuda'\n",
    "config.workers = 8\n",
    "\n",
    "print(f\"Projeto: {config.project_root}\")\n",
    "print(f\"Resultados: {config.results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset\n",
    "\n",
    "**IMPORTANTE**: Atualize com o caminho do seu dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATUALIZE ESTE CAMINHO\n",
    "dataset_path = '/path/to/your/data.yaml'\n",
    "\n",
    "if not Path(dataset_path).exists():\n",
    "    print(f\"‚ö†Ô∏è  Dataset n√£o encontrado: {dataset_path}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Dataset: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configura√ß√£o do Benchmark\n",
    "\n",
    "### Exemplo 1: Testar Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o do benchmark\n",
    "benchmark_config = BenchmarkConfig()\n",
    "benchmark_config.benchmark_name = 'epochs_benchmark'\n",
    "benchmark_config.num_divisions = 5\n",
    "\n",
    "# Define par√¢metros para testar\n",
    "benchmark_config.benchmark_params = {\n",
    "    'epochs': {\n",
    "        'min': 10,\n",
    "        'max': 50,\n",
    "        'type': 'int'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Par√¢metros fixos\n",
    "benchmark_config.fixed_params = {\n",
    "    'batch_size': 16,\n",
    "    'imgsz': 640\n",
    "}\n",
    "\n",
    "# Visualiza valores que ser√£o testados\n",
    "values = benchmark_config.get_benchmark_values('epochs')\n",
    "print(f\"Valores de epochs a testar: {values}\")\n",
    "print(f\"Total de testes: {len(values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo 2: M√∫ltiplos Par√¢metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark mais completo\n",
    "benchmark_config_multi = BenchmarkConfig()\n",
    "benchmark_config_multi.benchmark_name = 'multi_param_benchmark'\n",
    "benchmark_config_multi.num_divisions = 5\n",
    "\n",
    "benchmark_config_multi.benchmark_params = {\n",
    "    'epochs': {'min': 10, 'max': 50, 'type': 'int'},\n",
    "    'batch_size': {'min': 8, 'max': 32, 'type': 'int'},\n",
    "    'lr0': {'min': 0.001, 'max': 0.1, 'type': 'float'},\n",
    "    'optimizer': {'values': ['SGD', 'Adam', 'AdamW'], 'type': 'categorical'}\n",
    "}\n",
    "\n",
    "# Conta total de testes\n",
    "total_tests = sum(\n",
    "    len(benchmark_config_multi.get_benchmark_values(param))\n",
    "    for param in benchmark_config_multi.benchmark_params\n",
    ")\n",
    "\n",
    "print(f\"Total de testes a executar: {total_tests}\")\n",
    "print(\"\\nPar√¢metros:\")\n",
    "for param, config in benchmark_config_multi.benchmark_params.items():\n",
    "    values = benchmark_config_multi.get_benchmark_values(param)\n",
    "    print(f\"  {param}: {values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Executar Benchmark\n",
    "\n",
    "### Modo Sequencial (Recomendado para come√ßar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATEN√á√ÉO: Este processo pode levar bastante tempo!\n",
    "# Comece com poucos epochs para testar\n",
    "\n",
    "# Cria runner\n",
    "runner = BenchmarkRunner(config, benchmark_config)\n",
    "\n",
    "# Executa (sequencial)\n",
    "results = runner.run_benchmark(\n",
    "    dataset_path=dataset_path,\n",
    "    parallel=False\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BENCHMARK CONCLU√çDO!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total de testes: {results['total_tests']}\")\n",
    "print(f\"Bem-sucedidos: {results['successful_tests']}\")\n",
    "print(f\"Falhados: {results['failed_tests']}\")\n",
    "print(f\"Tempo total: {results['total_time']/60:.2f} minutos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo Paralelo (Avan√ßado)\n",
    "\n",
    "**Aten√ß√£o**: Requer m√∫ltiplas GPUs ou bastante RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execu√ß√£o paralela (CUIDADO: pode consumir muitos recursos)\n",
    "runner_parallel = BenchmarkRunner(config, benchmark_config)\n",
    "\n",
    "results_parallel = runner_parallel.run_benchmark(\n",
    "    dataset_path=dataset_path,\n",
    "    parallel=True,\n",
    "    max_workers=2  # Ajuste conforme recursos dispon√≠veis\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. An√°lise R√°pida dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extrai dados para DataFrame\n",
    "data = []\n",
    "for result in results['all_results']:\n",
    "    if result.get('success', False):\n",
    "        data.append({\n",
    "            'param': result['benchmark_param'],\n",
    "            'value': result['benchmark_value'],\n",
    "            'training_time': result['training_time'] / 60,\n",
    "            'mAP50-95': result.get('val_metrics', {}).get('mAP50-95', 0) * 100\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n",
    "\n",
    "# Estat√≠sticas\n",
    "print(\"\\nEstat√≠sticas por Par√¢metro:\")\n",
    "print(df.groupby('param')['mAP50-95'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualiza√ß√£o B√°sica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot mAP vs par√¢metro\n",
    "for param in df['param'].unique():\n",
    "    param_data = df[df['param'] == param]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(param_data['value'], param_data['mAP50-95'], marker='o', linewidth=2)\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel('mAP50-95 (%)')\n",
    "    plt.title(f'Impacto de {param} no mAP')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot tempo\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(param_data['value'], param_data['training_time'], marker='s', linewidth=2, color='orange')\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel('Tempo de Treinamento (min)')\n",
    "    plt.title(f'Impacto de {param} no Tempo')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Salvar Configura√ß√£o do Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva configura√ß√£o para reutilizar\n",
    "config_file = config.results_path / 'benchmark_config.json'\n",
    "benchmark_config.save(config_file)\n",
    "\n",
    "print(f\"‚úÖ Configura√ß√£o salva em: {config_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Carregar Benchmark Anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega resultados de benchmark anterior\n",
    "benchmark_name = 'epochs_benchmark'  # Ajuste conforme necess√°rio\n",
    "\n",
    "try:\n",
    "    loaded_results = runner.load_benchmark_results(benchmark_name)\n",
    "    print(f\"‚úÖ Benchmark carregado: {benchmark_name}\")\n",
    "    print(f\"Total de testes: {loaded_results['total_tests']}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ö†Ô∏è  Benchmark n√£o encontrado: {benchmark_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√≥ximos Passos\n",
    "\n",
    "Veja o notebook `04_analysis.ipynb` para:\n",
    "- Visualiza√ß√µes interativas com Bokeh\n",
    "- An√°lise estat√≠stica detalhada\n",
    "- Rankings de impacto de par√¢metros\n",
    "- Relat√≥rios autom√°ticos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
